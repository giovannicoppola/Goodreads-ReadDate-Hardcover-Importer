"""Sync Goodreads reading dates with Hardcover.

Usage:
  sync_hardcover.py <tsv_file> [--api-key=<file>] [--limit=<n>] [--log] [--help]
  sync_hardcover.py (-h | --help)

Options:
  <tsv_file>          Path to the TSV file generated by parse_goodreads.py
  --api-key=<file>    Path to the JSON file containing the Hardcover API key [default: hardcover_api_key.json]
  --limit=<n>         Maximum number of books to process (useful for testing) [default: 0]
  --log               Generate a log.txt file with all output
  -h --help          Show this help message and exit

Examples:
  sync_hardcover.py books.tsv
  sync_hardcover.py books.tsv --api-key=my_api_key.json
  sync_hardcover.py books.tsv --limit=5  # Process only 5 books
  sync_hardcover.py books.tsv --log      # Generate log file
"""

import csv
import json
import time
import sys
from datetime import datetime
from contextlib import contextmanager

import requests
from docopt import docopt


class Logger:
    """Handles logging to both console and file."""
    
    def __init__(self, log_to_file=False):
        self.log_to_file = log_to_file
        self.log_file = None
        if log_to_file:
            self.log_file = open("log.txt", "w", encoding="utf-8")
            self._write_log_header()
    
    def _write_log_header(self):
        """Write the log file header."""
        if self.log_file:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            self.log_file.write("=" * 80 + "\n")
            self.log_file.write("Hardcover Goodreads Reading Dates Updater\n")
            self.log_file.write(f"Started at: {timestamp}\n")
            self.log_file.write("=" * 80 + "\n\n")
    
    def log(self, message):
        """Log a message to both console and file if logging is enabled."""
        print(message)
        if self.log_file:
            self.log_file.write(message + "\n")
    
    def close(self):
        """Close the log file if it's open."""
        if self.log_file:
            self.log_file.write("\n" + "=" * 80 + "\n")
            self.log_file.write(f"Log completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            self.log_file.write("=" * 80 + "\n")
            self.log_file.close()


class HardcoverClient:
    """Client for interacting with the Hardcover API."""

    def __init__(self, api_key, api_url="https://api.hardcover.app/v1/graphql", logger=None):
        self.logger = logger or Logger()
        self.logger.log("\nInitializing HardcoverClient...")
        self.api_key = api_key
        self.api_url = api_url
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": api_key,  # The API key already includes "Bearer"
        }
        self.user_id = None  # Cache for user ID
        self.max_retries = 3  # Maximum number of retries for 504 errors
        self.base_delay = 2  # Base delay in seconds for exponential backoff

    def log(self, message):
        """Log a message using the logger."""
        self.logger.log(message)

    def _make_request_with_retry(self, query, variables=None, is_mutation=False):
        """Make an API request with retry logic for 504 errors."""
        retry_count = 0
        while retry_count < self.max_retries:
            try:
                request_data = {"query": query}
                if variables:
                    request_data["variables"] = variables

                response = requests.post(
                    self.api_url,
                    json=request_data,
                    headers=self.headers,
                )

                if response.status_code == 504:
                    retry_count += 1
                    if retry_count < self.max_retries:
                        delay = self.base_delay * (2 ** (retry_count - 1))  # Exponential backoff
                        self.log(f"⚠️ API Error 504: Gateway Timeout. Retrying in {delay} seconds... (Attempt {retry_count}/{self.max_retries})")
                        time.sleep(delay)
                        continue
                    else:
                        self.log("❌ Maximum retry attempts reached for 504 error")
                        return None, False

                return response, True

            except Exception as e:
                self.log(f"Error making API request: {str(e)}")
                return None, False

        return None, False

    def get_user_id(self):
        """Fetch the user ID from the Hardcover API."""
        if self.user_id is not None:
            self.log(f"Using cached user ID: {self.user_id}")
            return self.user_id

        self.log("\nGetting user ID...")
        query = """
        query {
          me {
            id
          }
        }
        """
        response, success = self._make_request_with_retry(query)
        if not success:
            return None

        if response.status_code == 200:
            data = response.json()
            if data.get("data", {}).get("me") and len(data["data"]["me"]) > 0:
                self.user_id = data["data"]["me"][0]["id"]
                self.log(f"User ID fetched: {self.user_id}")
                return self.user_id
            self.log("Error: Could not fetch user ID from response")
            self.log(f"Response: {data}")
            return None
        self.log(f"Error fetching user ID: HTTP {response.status_code}")
        self.log(f"Response: {response.text}")
        return None

    def find_book_by_goodreads_id(self, goodreads_id, dateFinished):
        """Find a book on Hardcover using its Goodreads ID."""
        # Ensure we have the user ID first
        user_id = self.get_user_id()
        if not user_id:
            return None

        query = """
        query FindBookByGoodreadsId($goodreadsId: String!, $userId: Int!) {
          book_mappings(where: {external_id: {_eq: $goodreadsId}}) {
            id
            book_id
            platform_id
            book {
              user_books(where: {user_id: {_eq: $userId}}) {
                id
                user_book_reads {
                  id
                  started_at
                  finished_at
                }
              }
            }
          }
        }
        """

        variables = {"goodreadsId": str(goodreads_id), "userId": int(user_id)}
        response, success = self._make_request_with_retry(query, variables)
        if not success:
            return None

        try:
            if response.status_code == 200:
                data = response.json()
                if (
                    "data" in data
                    and "user_book_reads"
                    in data["data"]["book_mappings"][0]["book"]["user_books"][0]
                ):
                    journey = data["data"]["book_mappings"][0]["book"]["user_books"][0][
                        "user_book_reads"
                    ]
                    if journey and len(journey) == 1:
                        if "id" in journey[0]:
                            return {
                                "journey_id": journey[0]["id"],
                                "started_at": journey[0]["started_at"],
                                "finished_at": journey[0]["finished_at"],
                            }
                        self.log("Warning: read journey not found")
                    elif len(journey) > 1:
                        self.log("Warning: multiple journeys found")
                        for this_journey in journey:
                            if this_journey["finished_at"] == dateFinished:
                                self.log(
                                    f"Choosing journey with matching finished date: {dateFinished}"
                                )
                                return {
                                    "journey_id": this_journey["id"],
                                    "started_at": this_journey["started_at"],
                                    "finished_at": this_journey["finished_at"],
                                }
                        self.log("No book journey found")
                else:
                    self.log(f"Unexpected response structure: {data}")
            else:
                self.log(f"API Error: {response.status_code}")
                self.log(f"Response: {response.text}")
            return None
        except Exception as e:
            self.log(f"Error finding book: {str(e)}")
            self.log(
                f"Response: {response.text if 'response' in locals() else 'No response'}"
            )
            return None

    def update_reading_date(self, journey_id, date_started, date_finished):
        """Update the reading date for a book on Hardcover."""
        # Ensure we have the user ID first
        user_id = self.get_user_id()
        if not user_id:
            self.log("Error: Could not get user ID")
            return False

        mutation = """
            mutation updateReadingDate ($journeyId: Int!, $dateStarted: date!, $dateFinished: date!) {
                 update_user_book_read(
                     id: $journeyId
                     object: {started_at: $dateStarted, finished_at: $dateFinished}
                   ) {
                     id
                     user_book_read {
                       finished_at
                       started_at
                     }
                   }
                 }
        """

        variables = {
            "journeyId": int(journey_id),
            "dateStarted": date_started,
            "dateFinished": date_finished,
        }

        response, success = self._make_request_with_retry(mutation, variables, is_mutation=True)
        if not success:
            return False

        if response.status_code == 200:
            data = response.json()
            if "errors" in data:
                self.log(f"GraphQL errors: {data['errors']}")
                return False
            return True
        return False


def load_api_key(api_key_file, logger):
    """Load the API key from a JSON file."""
    try:
        with open(api_key_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("api_key")
    except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
        logger.log(f"Error loading API key: {e}")
        return None


def format_date(date_str, logger):
    """Convert date from various formats to yyyy-mm-dd format."""
    if not date_str:
        return None

    try:
        # Try parsing with different formats
        for fmt in ["%m/%d/%y", "%b %Y", "%Y-%m-%d"]:
            try:
                date_obj = datetime.strptime(date_str, fmt)
                return date_obj.strftime("%Y-%m-%d")
            except ValueError:
                continue
        logger.log(f"Warning: Could not parse date: {date_str}")
        return None
    except Exception as e:
        logger.log(f"Error formatting date {date_str}: {str(e)}")
        return None


def process_tsv_file(tsv_file, client, limit=0):
    """Process a TSV file and update reading dates on Hardcover."""
    total_books = 0
    books_updated = 0
    
    try:
        with open(tsv_file, "r", encoding="utf-8") as tsvfile:
            reader = csv.DictReader(tsvfile, delimiter="\t")
            total_books = sum(1 for _ in reader)  # Count total rows
            tsvfile.seek(0)  # Reset file pointer
            reader = csv.DictReader(tsvfile, delimiter="\t")  # Recreate reader

            if limit > 0:
                client.log(f"\n⚠️ Processing limited to {limit} books (for testing)")
                total_books = min(total_books, limit)

            for row_num, row in enumerate(reader, 1):
                if limit > 0 and row_num > limit:
                    client.log(f"\n⚠️ Reached limit of {limit} books. Stopping.")
                    break

                try:
                    client.log(f"\n📍Processing row {row_num}")
                    goodreads_id = row["Goodreads ID"]
                    date_started_tsv = row["Date Started"]
                    date_finished_tsv = row["Date Read"]
                    book_title = row["Book Title"]

                    if not goodreads_id or not date_started_tsv:
                        client.log(f"Skipping row with missing data: {book_title}")
                        continue

                    # Format dates
                    date_started = format_date(date_started_tsv, client.logger)
                    date_finished = format_date(date_finished_tsv, client.logger)

                    if not date_started:
                        client.log(f"  ❌ Could not parse start date for book: {book_title}")
                        continue

                    client.log(book_title)

                    # Find book on Hardcover
                    journey_id_data = client.find_book_by_goodreads_id(
                        goodreads_id, date_finished
                    )

                    if not journey_id_data:
                        client.log(f"  ❌ Book not found on Hardcover: {book_title}")
                        continue

                    client.log("\nUpdating reading dates ...")

                    # Check if dates are different from current values
                    dates_changed = (
                        journey_id_data["started_at"] != date_started
                        or journey_id_data["finished_at"] != date_finished
                    )

                    # Update reading date
                    if client.update_reading_date(
                        journey_id_data["journey_id"], date_started, date_finished
                    ):
                        if dates_changed:
                            books_updated += 1
                        client.log(
                            f"✅ Book '{book_title}' updated with read dates: {date_started} to {date_finished or date_started}"
                        )
                    else:
                        client.log(f"  ❌ Failed to update reading date for '{book_title}'")

                    # Add a small delay to be respectful to the API
                    time.sleep(1)
                except Exception as e:
                    client.log(f"Error processing row {row_num}: {str(e)}")
                    client.log(f"Row data: {row}")
                    client.log(f"Error type: {type(e)}")
                    client.log(f"Error details: {str(e)}")
                    continue

    except FileNotFoundError:
        client.log(f"Error: TSV file not found: {tsv_file}")
    except Exception as e:
        client.log(f"Error processing TSV file: {e}")
        client.log(f"Error type: {type(e)}")
        client.log(f"Error details: {str(e)}")
    
    # Print summary
    client.log("\n📊 Summary:")
    client.log(f"Total books evaluated: {total_books}")
    client.log(f"Books with dates updated: {books_updated}")


def main():
    """Main function to handle command line arguments and process the TSV file."""
    # Parse command line arguments
    args = docopt(__doc__)

    # Initialize logger
    logger = Logger(log_to_file=args.get("--log", False))
    logger.log("Starting script...")

    # Load API key
    logger.log(f"Loading API key from: {args['--api-key']} ...")
    api_key = load_api_key(args["--api-key"], logger)
    if not api_key:
        logger.log("Failed to load API key. Exiting.")
        return
    logger.log("API key loaded successfully")

    # Get limit if specified
    limit = int(args.get("--limit", 0))

    # Create client and process file
    client = HardcoverClient(api_key, logger=logger)
    logger.log(f"Processing TSV file: {args['<tsv_file>']}")
    process_tsv_file(args["<tsv_file>"], client, limit)
    logger.log("\n👍️ Script completed.")
    
    # Close the log file if it was opened
    logger.close()


if __name__ == "__main__":
    main()
